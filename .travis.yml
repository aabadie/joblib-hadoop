sudo: required

language: python

python:
    - "3.5"

services:
    - docker

before_install:
    - sudo apt-get update
    - sudo apt-get install -o Dpkg::Options::="--force-confold" --force-yes -y docker-engine
    - cd docker
    - docker system prune -a
    - docker-compose up -d
    - cd ..

install:
    - wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh;
    - bash miniconda.sh -b -p $HOME/miniconda
    - export PATH="$HOME/miniconda/bin:$PATH"
    - conda config --set always_yes yes --set changeps1 no
    - conda update -q conda
    - conda create -q -n test-environment python=$TRAVIS_PYTHON_VERSION libhdfs3 -c conda-forge
    - source activate test-environment
    - pip install -r requirements.txt .
    # Some checks on Hadoop cluster
    - docker-compose --version
    - docker --version
    - docker ps
    - docker network ls
    - docker network inspect docker_joblib_hadoop
    - cd docker && docker-compose ps && cd ..

script:
    # Run local unit tests first
    - pytest
    # All examples/tests are run from a docker container
    - cd docker
    # HDFS store backend example
    - docker-compose run --rm --name testnode nodemanager python examples/joblib_hdfs_multiply.py
    # YARN parallel backend example
    - docker-compose run --rm --name testnode nodemanager python examples/joblib_yarn_parallel.py
    # Unit testing from root of project
    - docker-compose run --rm --name testnode -e NAMENODE=namenode nodemanager make docker-test
    - cd ..

after_success:
    # Send coverage results to codecov
    - codecov

after_failure:
    - cd && cd docker
    # Cleanup
    - docker-compose stop
    - docker-compose rm -f

notifications:
      email: false
